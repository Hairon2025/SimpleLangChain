# app/cli.py
import os
import getpass
from src.loader import load_docs_from_config
from src.vectorstore import get_vectorstore
from src.llm import get_llm
from src.generator import get_rag_prompt
from src.graph import create_rag_graph
import yaml

def main():
    # åŠ è½½é…ç½®
    with open("./config/settings.yaml", "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # è®¾ç½® API Key
    if not os.environ.get("DASHSCOPE_API_KEY"):
        print("ğŸ” è¯·è¾“å…¥ DASHSCOPE API Key:")
        os.environ["DASHSCOPE_API_KEY"] = getpass.getpass()

    # åˆå§‹åŒ–ç»„ä»¶
    print("ğŸš€ åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
    vectorstore = get_vectorstore(config["vectorstore"]["persist_directory"])

    # å¦‚æœæ•°æ®åº“ä¸ºç©ºï¼Œå¯¼å…¥æ•°æ®
    if not vectorstore.get()["documents"]:
        print("ğŸ“¥ å‘é‡åº“ä¸ºç©ºï¼Œæ­£åœ¨åŠ è½½ç½‘é¡µå†…å®¹...")
        splits = load_docs_from_config(config)
        vectorstore.add_documents(splits)
        print("âœ… æ•°æ®å·²å¯¼å…¥å‘é‡åº“")
    else:
        print("ğŸ” ä½¿ç”¨å·²æœ‰å‘é‡åº“")

    llm = get_llm(config["model"]["llm"], config["model"]["temperature"])
    prompt = get_rag_prompt(config["rag"]["prompt"])
    graph = create_rag_graph(vectorstore, llm, prompt)

    # å¼€å§‹äº¤äº’
    print("\nğŸ’¬ æ¬¢è¿ä½¿ç”¨ RAG åŠ©æ‰‹ï¼è¾“å…¥ 'quit' é€€å‡ºã€‚\n")
    while True:
        try:
            question = input("â“ é—®é¢˜: ").strip()
            if question.lower() in ["quit", "q", "Q", "exit"]:
                break
            if not question:
                continue
            result = graph.invoke({"question": question})
            print(f"âœ… ç­”æ¡ˆ: {result['answer']}\n")
        except KeyboardInterrupt:
            break
    print("\nğŸ‘‹ å†è§ï¼")

if __name__ == "__main__":
    main()